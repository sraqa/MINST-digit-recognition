{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, Flatten, MaxPool2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of train data (42000, 785)\n",
      "The shape of the test data (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "print(\"The shape of train data\", train.shape)\n",
    "print(\"The shape of the test data\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the images are flattened (each row contains values for a single image)\n",
    "# we need to reshape it to get the immage matrix (grayscale pixel values in a 28 x 28 matrix)\n",
    "# but first, we seprate labels and predictors (y and x respectively)\n",
    "# and convert from Pandas dataframe into numpy matrix (that's what the .values does)\n",
    "\n",
    "X = (train.iloc[:, 1:].values).astype('float32')\n",
    "y = (train.iloc[:, 0].values).astype('int32')\n",
    "X_test = test.values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape the matrix\n",
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 10 # digits 0 - 9\n",
    "\n",
    "X_train = X.reshape(X.shape[0], img_rows, img_cols)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the images for sanity check\n",
    "\n",
    "for i in range(5, 8):\n",
    "    plt.subplot(130 + (-4+i))\n",
    "    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.title(y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add another dimension for color channel\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the pixel values for easier processing\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode labels with one-hot encoder (convert to separate categories)\n",
    "y_train = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and validation set (used only for image augmentation, otherwise done at fitting)\n",
    "X_gen, X_val, y_gen, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# apply some augmentation to the images data to increase training data\n",
    "datagen = ImageDataGenerator(rotation_range=10,\n",
    "                            zoom_range=0.1,\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1)\n",
    "datagen.fit(X_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(5, 5),\n",
    "                activation='relu',\n",
    "                padding='same', # pads the \"frames\" of the image with 0's, so that convolution reaches the edges\n",
    "                input_shape=(img_rows, img_cols, 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(32, kernel_size=(5, 5),\n",
    "                padding='same',\n",
    "                activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(12, kernel_size=(3, 3),\n",
    "                padding='same',\n",
    "                activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),\n",
    "                padding='same',\n",
    "                activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),\n",
    "                padding='same',\n",
    "                activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 12)        3468      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 12)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 14, 14, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 64)        6976      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 879,478\n",
      "Trainable params: 879,478\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# show the summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 2/90 [..............................] - ETA: 1:02:46 - loss: 2.3015 - acc: 0.1048"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9a9dd015792c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m model.fit_generator(datagen.flow(X_gen, y_gen, batch_size=420),\n\u001b[1;32m      3\u001b[0m                    \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                    validation_data=(X_val, y_val))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    212\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit_generator(datagen.flow(X_gen, y_gen, batch_size=420),\n",
    "                   epochs=20,\n",
    "                   validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "preds = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save prediction into a Pandas dataframe and save it to .csv\n",
    "submission = pd.DataFrame({'ImageId': list(range(1, len(preds)+1)), 'Label': preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
